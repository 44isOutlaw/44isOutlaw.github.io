<!DOCTYPE html><html lang="ko" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Dnn을 이용한 데이터 분류" /><meta property="og:locale" content="ko" /><meta name="description" content="DNN을 이용한 데이터 분류" /><meta property="og:description" content="DNN을 이용한 데이터 분류" /><link rel="canonical" href="https://44isoutlaw.github.io/posts/DNN%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EB%A5%98/" /><meta property="og:url" content="https://44isoutlaw.github.io/posts/DNN%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EB%A5%98/" /><meta property="og:site_name" content="Toolbox 44" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-07-25T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Dnn을 이용한 데이터 분류" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-07-25T00:00:00+09:00","datePublished":"2022-07-25T00:00:00+09:00","description":"DNN을 이용한 데이터 분류","headline":"Dnn을 이용한 데이터 분류","mainEntityOfPage":{"@type":"WebPage","@id":"https://44isoutlaw.github.io/posts/DNN%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EB%A5%98/"},"url":"https://44isoutlaw.github.io/posts/DNN%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EB%A5%98/"}</script><title>Dnn을 이용한 데이터 분류 | Toolbox 44</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Toolbox 44"><meta name="application-name" content="Toolbox 44"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> </a></div><div class="site-title mt-3"> <a href="/">Toolbox 44</a></div><div class="site-subtitle font-italic">학교와 연구실에서 배운 지식들을 나중에 기록하는 용도입니다.</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/44isOutlaw" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['wpsltm9204','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Dnn을 이용한 데이터 분류</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Dnn을 이용한 데이터 분류</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1658674800" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Jul 25, 2022 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://twitter.com/username">your_full_name</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="5425 words"> <em>30 min</em> read</span></div></div></div><div class="post-content"><h1 id="dnn을-이용한-데이터-분류">DNN을 이용한 데이터 분류</h1><h2 id="ⅰ-intro"><span class="mr-2">Ⅰ. Intro</span><a href="#ⅰ-intro" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Machine learning 기법 중 하나인 NN(Neural Network)에 대하여 간단히 알아보고, 이를 구현한 keras 모델을 이용해 데이터를 분류하는 과정을 본문에 정리했다.</p><h2 id="ⅱ-neural-network"><span class="mr-2">Ⅱ. Neural Network</span><a href="#ⅱ-neural-network" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><img data-src="https://github.com/44isOutlaw/44isOutlaw.github.io/blob/master/assets/img/DNN/1.png?raw=true" alt="image-20220717204505546" data-proofer-ignore></p><p>Neural Network(이하 NN)은 Machine learning 기법 중 하나로, 인간의 뇌세포를 모방하여 만들어졌다. 여러가지 입력 신호를 받아 하나의 결과를 출력하는 아이디어를 채용하여, 아래 사진과 같은 모양을 만들어냈다.</p><p><img data-src="https://github.com/44isOutlaw/44isOutlaw.github.io/blob/master/assets/img/DNN/ICLH_Diagram_Batch_01_03-DeepNeuralNetwork-WHITEBG.jpg?raw=true" alt="NN" style="zoom: 33%;" data-proofer-ignore></p><p>(출처 : www.ibm.com)</p><p>NN은 input layer, hidden layer 그리고 output layer로 구성되어 있으며, 각 layer의 node는 양 옆의 layer의 모든 node들과 연결되어 있다. NN의 학습 과정을 간단히 설명하면, input layer가 데이터를 받아(입력 신호에 대응됨) hidden layer에서 일련의 연산을 거쳐, output layer로 결과를 출력한다. 여기서 hidden layer의 개수에 따라, 구조에 따라 명칭이 달라지는데, 위 그림과 같이 hidden layer가 여러개인 경우에는 Deep Neural Network(이하 DNN)이라고 한다.</p><p><img data-src="https://github.com/44isOutlaw/44isOutlaw.github.io/blob/master/assets/img/DNN/2.PNG?raw=true" alt="2" data-proofer-ignore></p><p>그렇다면 이러한 NN의 hidden layer에서 무슨 일이 일어나는지 궁금해지는데, 각 node는 위 그림과 같이 input data(위 그림의 x)를 받아 가중치(위 그림의 w)를 곱하고 bias(b)를 더한 후 activation function을 거쳐 나온 Y를 다음 node에 전달한다. 이 때, activation function은 relu, sigmoid, tanh, softmax 등등 다양한 종류가 있으며 가중치 및 bias와 연산을 거친 값을 특정한 값으로 출력한다. 다루는 dataset에 따라 적절한 activation function을 골라야 하는데, 기회가 된다면 후술하도록 한다. (https://keras.io/ko/activations/ 에 keras에서 이용 가능한 activation function이 정리되어 있음)</p><p><img data-src="https://github.com/44isOutlaw/44isOutlaw.github.io/blob/master/assets/img/DNN/3.PNG?raw=true" alt="3" data-proofer-ignore></p><p>다시 돌아와서, NN을 학습한다는 것은 cost function을 최소화하는 가중치 w를 구하는 것을 의미한다. Cost function은 우리가 익히 알고있는 Mean Squared Error(이하 MSE)등의 함수로, 우리가 학습 과정에서 model이 지향하도록 제시하는 output값과 model이 예측하는 output값을 비교하는 함수이다.(이렇게 우리가 결과값을 제시하여 학습시키기 때문에 이를 supervised learning이라고 표현한다)</p><p>위 그림과 같이 cost function J에서 w값을 조정하여 J가 최소가 되는 w를 찾아내는 과정은 J의 w에 대한 편미분값의 일정 비율을 빼는 방식을 따르며, 이 비율을 learning rate라고 한다. Learning rate을 설정할 때는 너무 작으면 학습 시간이 오래 걸리고, 너무 크면 최소가 되는 지점을 벗어날 수 있다는 점을 유의하여야 한다. 이러한 과정을 output layer에서부터 역으로 layer들을 지나며 w값을 업데이트하는 방식으로 학습이 진행된다.(이를 backpropagation이라고 한다)</p><h2 id="ⅲ-keras의-dnn-model"><span class="mr-2">Ⅲ. Keras의 DNN Model</span><a href="#ⅲ-keras의-dnn-model" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Keras는 tensorflow가 제공하는 python 기반 machine learning model이다. 이하는 Keras를 scikit-learn의 분류 dataset에 직접 적용한 과정을 소개하면서 어떤 과정을 거쳐 model을 만들고 학습시키는지 작성하도록 한다.</p><h3 id="숫자-손글씨-분류-model"><span class="mr-2">숫자 손글씨 분류 Model</span><a href="#숫자-손글씨-분류-model" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> 
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span> <span class="c1">#np,pd 모두 data를 손질하기 위한 tool
</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span> <span class="c1">#이미지 등을 plot를 위한 module
</span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span> <span class="c1">#이번 예제의 dataset
</span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span> <span class="c1">#data 정규화를 위한 module
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span> <span class="c1">#train용,test용으로 데이터를 나눔
</span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span> <span class="c1">#tensorflow 안에 keras가 있다
</span><span class="kn">import</span> <span class="nn">random</span>
</pre></table></code></div></div><p>사실 숫자 손글씨를 분류하는 dataset는 MNIST라는 좋은 dataset이 있지만, MNIST는 data가 3차원으로 되어 있어 DNN으로는 다루기 힘드므로, 이번엔 scikit-learn에 있는 2차원 dataset을 이용했다. (MNIST는 추후 업로드할 CNN의 예제에서 소개하도록 한다.)</p><h4 id="data-손질"><span class="mr-2">Data 손질</span><a href="#data-손질" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">digits</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">digits</span><span class="p">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">digits</span><span class="p">.</span><span class="n">target</span>
</pre></table></code></div></div><p>위 코드를 통해 dataset를 불러올 수 있다. load_digits()로 불러낸 dataset는 data와 target으로 구성되어 있으며 각각 x, y으로 정의하였다. 이를 뜯어보면..</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">target</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1">#shape는 np의 함수로, 배열의 구조를 보여줌
</span><span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">target</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">gray</span><span class="p">()</span> <span class="c1">#회색으로 이미지 출력
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">15</span><span class="p">):</span>
  
  <span class="n">plt</span><span class="p">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="c1">#dataset의 1번부터 14번까지 이미지 출력
</span></pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="p">(</span><span class="mi">1797</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span> <span class="c1">#(샘플 수, input 수)
</span><span class="p">(</span><span class="mi">1797</span><span class="p">,)</span> <span class="c1">#(샘플 수, output 수)
</span><span class="p">[[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">5.</span> <span class="p">...</span>  <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span> <span class="p">...</span> <span class="mf">10.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span> <span class="p">...</span> <span class="mf">16.</span>  <span class="mf">9.</span>  <span class="mf">0.</span><span class="p">]</span>
 <span class="p">...</span>
 <span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">1.</span> <span class="p">...</span>  <span class="mf">6.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">2.</span> <span class="p">...</span> <span class="mf">12.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span> <span class="mf">10.</span> <span class="p">...</span> <span class="mf">12.</span>  <span class="mf">1.</span>  <span class="mf">0.</span><span class="p">]]</span> <span class="c1">#(data의 내용)
</span><span class="p">[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span> <span class="p">...</span> <span class="mi">8</span> <span class="mi">9</span> <span class="mi">8</span><span class="p">]</span> <span class="c1">#(target의 내용)
</span><span class="o">&lt;</span><span class="n">Figure</span> <span class="n">size</span> <span class="mi">432</span><span class="n">x288</span> <span class="k">with</span> <span class="mi">0</span> <span class="n">Axes</span><span class="o">&gt;</span>

</pre></table></code></div></div><p><img data-src="https://github.com/44isOutlaw/44isOutlaw.github.io/blob/master/assets/img/DNN/one.png?raw=true" alt="one" data-proofer-ignore></p><p><img data-src="https://github.com/44isOutlaw/44isOutlaw.github.io/blob/master/assets/img/DNN/two.png?raw=true" alt="two" data-proofer-ignore> <img data-src="https://github.com/44isOutlaw/44isOutlaw.github.io/blob/master/assets/img/DNN/three.png?raw=true" alt="3" data-proofer-ignore></p><p>이 결과로 미루어 보아 dataset에 1797의 sample이 있으며, input 수는 64개이며 input는 0~16 사이의 정수로 이루어져 있음을 짐작할 수 있다. 이 64개의 input는 숫자 사진을 8x8로 나누어 각 구역의 명도를 나타내고 있다.(숫자가 높을수록 밝은 듯 하다.) 한편, target의 output은 내용으로 보아 그림이 의도한 수가 어떤 숫자인지 나타내고 있는 듯 한데, 구조가 (1797,)으로 뭔가 이상함을 느낄 수 있다. 다만 target의 output이 1개임은 자명하므로, reshape 함수를 이용하여 해결할 수 있다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">y</span> <span class="o">=</span> <span class="n">digits</span><span class="p">.</span><span class="n">target</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1797</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1">#구조를 (1797,1)로 바꾸기
</span><span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="p">(</span><span class="mi">1797</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1">#적절히 수정되었음을 알 수 있다.
</span></pre></table></code></div></div><p>이제 우리는 dataset이 어떤 모양인지 파악했다. 하지만, input은 0~16 사이 정수이며 output은 0~9 사이 정수이므로 어느정도 차이가 있는 상태인데, 이 수치 그대로 model에 학습시킨다면 가중치(w)가 의도와 다르게 학습될 수 있다. 이를 해결하기 위해 우리는 데이터를 정규화해주어야 한다. (솔직히 이러한 dataset에도 정규화가 필요한지에는 의문점이 남아있으나, 전혀 성질, 범위가 다른 input이 결합되어 있는 dataset이라면 이 과정을 필수적으로 수행해야 적절히 model을 학습시킬 수 있으므로 유의해야 한다)</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">min_max_scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">MinMaxScaler</span><span class="p">()</span> <span class="c1">#preprocessing module 속 MinMaxScaler 메소드
</span><span class="n">x</span> <span class="o">=</span> <span class="n">min_max_scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1">#fit-수치를 조정 transform-적용. fit_transform은 동시에
</span><span class="n">y</span> <span class="o">=</span> <span class="n">min_max_scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></table></code></div></div><p>MinMaxScaler()는 데이터들을 0~1사이 수치로 조정해준다. 이 메소드는 인자로 feature_range=(a,b)를 받아 a,b사이로 수치를 조정할 수 있다. 본문에서는 fit_transform을 이용하여 x,y를 0~1사이로 정규화 시켰다. scikit-learn의 preprocessing module은 MinMaxScaler 뿐만 아니라, StandardScaler, RobustScaler 등 다양한 정규화 함수를 갖고 있으니 상황에 맞게 사용하기를 권장한다.</p><p>마지막으로, 이렇게 손질한 data를 train_test_split 메소드로 train용, test용으로 나누어야 한다. 이렇게 train용, test용으로 데이터를 나누는 이유는 학습의 결과가 잘 나타났는지 확인하기 위함이다.(모델을 학습시킨 데이터로 test해봤자 당연히 좋은 결과가 나오기 때문이다)</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">img</span> <span class="o">=</span> <span class="n">digits</span><span class="p">.</span><span class="n">images</span> <span class="c1">#나중에 test 이미지를 plot하기 위해 미리 정의했다
</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span> <span class="c1">#난수가 매번 같은 수를 가짐
</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">img_train</span><span class="p">,</span> <span class="n">img_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span> <span class="c1">#x,y,img를 train과 test로 나눔
</span></pre></table></code></div></div><p>이와 같이 train_test_split를 정의하면 x, y, img에서 test_size의 비율만큼 test용 data, train용 data로 분류한다. 이 때, random_state가 전체 dataset에서 무작위로 test data를 수집하도록 하며, 이에 앞서 np.random.seed를 정의하여 x, y, img에서 같은 위치의 data를 수집하도록 해야한다. 이를 정의하지 않는 경우 random의 숫자가 x를 구할때와 y, img를 구할 때와는 달라져 x, y, img의 test값이 서로 일치하지 않는 결과가 발생하게 된다. 이렇게 data를 나누는 것에 성공했다면, dataset의 손질은 끝났고 모든 준비를 마친 것이다.</p><h4 id="model-정의-및-학습"><span class="mr-2">Model 정의 및 학습</span><a href="#model-정의-및-학습" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>Keras model은 두가지 방법으로 정의할 수 있다. 이하의 2개의 모델 정의 방법은 하나의 예시로 참고하면 된다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">_initializer</span> <span class="o">=</span> <span class="s">'glorot_normal'</span>
<span class="n">_activation</span> <span class="o">=</span> <span class="s">'relu'</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
                             <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">_initializer</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">_activation</span><span class="p">,</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">64</span><span class="p">,)),</span>
                             <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">_initializer</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">_activation</span><span class="p">),</span>
                             <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">])</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">_initializer</span> <span class="o">=</span> <span class="s">'glorot_normal'</span>
<span class="n">_activation</span> <span class="o">=</span> <span class="s">'relu'</span>

<span class="nb">input</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,))</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">_initializer</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span> <span class="n">_activation</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">_initializer</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span> <span class="n">_activation</span><span class="p">)(</span><span class="n">D</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">D</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">output</span><span class="p">)</span>
</pre></table></code></div></div><p>아래의 메소드를 이용하여 model의 구조를 한 눈에 확인할 수 있다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
<span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">show_shapes</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre>Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_31 (Dense)            (None, 128)               8320      
                                                                 
 dense_32 (Dense)            (None, 512)               66048     
                                                                 
 dense_33 (Dense)            (None, 1)                 513       
                                                                 
=================================================================
Total params: 74,881
Trainable params: 74,881
Non-trainable params: 0
_________________________________________________________________
</pre></table></code></div></div><p><img data-src="https://github.com/44isOutlaw/44isOutlaw.github.io/blob/master/assets/img/DNN/seq.png?raw=true" alt="seq" data-proofer-ignore></p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre>Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_9 (InputLayer)        [(None, 64)]              0         
                                                                 
 dense_25 (Dense)            (None, 128)               8320      
                                                                 
 dense_26 (Dense)            (None, 512)               66048     
                                                                 
 dense_27 (Dense)            (None, 1)                 513       
                                                                 
=================================================================
Total params: 74,881
Trainable params: 74,881
Non-trainable params: 0
_________________________________________________________________
</pre></table></code></div></div><p><img data-src="https://github.com/44isOutlaw/44isOutlaw.github.io/blob/master/assets/img/DNN/model1.png?raw=true" alt="mod" data-proofer-ignore></p><p>보다시피, 두 model의 정의 방법은 전혀 다르지만 실제로 model의 형태는 동일하다. Initializer, activation은 일단 무시하고(실제로 없어도 정의가 되긴 한다) 구조를 정의하는 방법의 차이에 대해 설명하면, Sequential은 그 내부에 정의할 layer가 한 줄로 이어지도록 사전에 의도하는 것이다. 한편 input부터 차례대로 정의하는 방법은 의도하면 여러 input, output을 설정할 수도 있고 여러 개의 NN model을 병렬 구조로 합칠수도 있어 높은 자유도를 갖지만, sequential에 비해 정의하기에 상대적으로 번거롭다.</p><p><img data-src="https://github.com/44isOutlaw/44isOutlaw.github.io/blob/master/assets/img/DNN/merge.png?raw=true" alt="merge" data-proofer-ignore></p><p>이렇게 생긴 model은 후자의 방법으로 정의가 가능하다. 다만 이번에는 한 줄의 DNN 구조를 정의하고자 하므로, Sequential 함수를 이용하여 model을 정의하도록 한다.</p><p>Sequential 내부를 살펴보면, Dense layer가 있는데 이는 hidden layer 또는 output layer로 정의될 수 있다. Dense의 맨 처음 인자를 통해 node 수를 정의할 수 있으며, 첫번째 dense layer에서는 input_shape 인자로 input의 모양을 설정할 수 있다.(설정하지 않아도 입력되는 input을 알아서 감지하긴 한다.) 특히 output 역할을 하는 dense layer는 output 개수와 동일한 node를 갖도록 정의하여야 한다. 이외에는 자유롭게 Dense를 더 늘려 layer의 개수를 늘리거나, node 수를 변경해가며 dataset에 최적화된 model을 찾는 것 뿐이다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">_initializer</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span> <span class="n">_activation</span><span class="p">)</span>
</pre></table></code></div></div><p>이제 initializer, activation에 대해 설명한다. Activation은 처음에 짐작했듯이, activation function의 설정이다. 설정하지 않아도 dense layer 정의는 가능하나, activation을 설정하지 않으면 정상적인 학습은 불가능하다. 본문에서는 ‘relu’라는 activation function을 설정하였는데, 이는 REctified Linear Unit의 줄임으로 0 이하의 값은 모두 0으로, 0 이상은 선형이 되도록 수치를 변경하는 activation function이다. 우리의 dataset의 output이 0~9(물론 정규화되었지만)임을 고려하면, output이 왜곡될 가능성이 낮아보인다.</p><p>Initializer는 가중치(w)들의 초기값을 설정하는 인자이다. 예측할 수는 없겠지만, 초기값이 최종 가중치값과 너무 다르다면 학습에 어려움이 따를 수 있음을 예상할 수 있다. 반대로 말하면, 초기값이 잘 설정된다면 model의 학습에 크게 기여할 수 있다는 것이다. 본문에서 설정한 ‘glorot_normal’은 Xavier normal initializer라고도 불리는 가장 보편적인 initializer로, 이전 hidden layer의 노드 수와 현재의 노드 수를 이용해 계산한 값을 표준편차로 가중치를 정규화시킨다. 이렇게 initializer, activation을 hidden layer에 적용시켜 model을 정의하였다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="n">drop_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">_initializer</span> <span class="o">=</span> <span class="s">'glorot_normal'</span>
<span class="n">_activation</span> <span class="o">=</span> <span class="s">'relu'</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
                             <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">_initializer</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">_activation</span><span class="p">,</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">64</span><span class="p">,)),</span>
                             <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">_initializer</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">_activation</span><span class="p">),</span>
                             <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">drop_rate</span><span class="p">),</span>
                             <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">_initializer</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">_activation</span><span class="p">),</span>
                             <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">])</span>
</pre></table></code></div></div><p>Model의 정의를 마치기 전에, 성능 향상을 위한 장치를 하나 소개한다. 바로 Dropout layer인데, 이는 무작위로 가중치(w)의 값을 입력된 비율만큼 제거한다. 즉, Dropout layer는 model이 train data을 과하게 학습하여 test data의 target를 맞추지 못하는(overfitting) 상황을 가중치를 고의적으로 버려 완화시켜 줌으로써 model의 성능을 향상시킬 수 있다. 만약 model이 overfitting되고 있다면, dropout layer를 사용하는 것을 고려해야 할 것이다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">_optimizer</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s">'MSE'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</pre></table></code></div></div><p>Model의 정의가 완료되면 학습시키기 전에 compile 작업이 필요하다. Compile에서는 최적의 w를 찾을 방법(optimizer)를 설정해주어야 하며, cost function(loss)을 정의한다. metrics에는 성능지표로 이용할 함수를 정의해줄 수 있는데, 본문과 같이 분류학습의 경우에는 실제 target값과 학습 target값을 비교하는 ‘accuracy’가 적절한 지표가 될 수 있다. 여기서 optimizer는 Adam으로 정의하였는데 이는 Ⅱ절의 gradient 방식의 일종으로 가장 보편적으로 사용되는 optimizer이다. Optimizer는 learning_rate를 설정해주어야 하는데, 이 값이 너무 크면 loss function의 최저값을 지나칠수도 있으며 너무 작으면 학습 시간이 매우 오래 걸릴 수 있으므로 적절한 값을 설정하여야 한다. loss는 익숙한 MSE로 설정하였다.</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>_batch_size = 64
reduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', patience = 10, factor = 0.9)
ES = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 200, restore_best_weights = True)

history = model.fit(x_train, y_train, epochs = 3000, batch_size = _batch_size, callbacks = [reduceLR, ES], validation_split = 0.1, verbose = 1)
</pre></table></code></div></div><p>드디어 model을 학습시킬 수 있게 되었다. Model의 학습은 fit 함수를 이용하여 수행하며 첫번째와 두번째 인자로 x_train과 y_train을 입력해야 한다. epochs는 전체 데이터셋을 1회 학습한 상태로, 학습 횟수를 의미한다. batch size는 한번에 다루는 data의 갯수를 의미한다. x, y값 및 epochs, batch size는 필수적으로 정의되어야 한다. Callbacks와 validation_split 등의 인자는 model의 학습을 돕는 장치들로 선택적으로 정의하면 된다.</p><p>먼저, model.fit을 history에 정의하는 이유는 epoch마다 결과값을 확인할 수 있도록 출력하기 위함이다. 맨 뒤의 인자인 verbose가 1일 때 결과값이 출력되는데, verbose를 0으로 설정하면 학습이 끝날때까지 어떤 메세지도 출력하지 않는다. 다음으로, Epochs는 model이 overfitting되거나 underfitting되지 않도록 적절히 설정해야 하며, batch size는 너무 작으면 학습 속도가 느려지고, 너무 크면 메모리의 한계로 문제가 발생할 수 있다는 점을 유의하여야 한다.</p><p>Fit의 인자중에는 validation_split이 있는데, 이를 설정하면 train data의 0.1(입력값)의 비율만큼은 validation을 수행하는데 사용하게 된다. Validation 과정은 epoch마다 학습된 model에 validation data를 입력하여 평가하게 되며, 위 compile에서 설정한 그대로 validation으로 계산한 loss(val_loss)와 accuracy(val_accuracy)를 추가적으로 출력하게 된다. 이러한 출력물들은 학습 과정에서 나오는 loss와 accuracy보다 신뢰성이 있으며 model이 overfitting되지 않고 적절히 학습하고 있는지 평가할 수 있는 중요한 지표가 된다.</p><p>Callbacks에는 [reduceLR, ES]를 정의하였는데, reduceLR은 ReduceLROnPlateau라는 메소드를 정의한 것으로, monitor(‘val_loss’)가 patience(10) epochs 동안 성능이 좋아지지 않는다면 learning rate(compile에서 정의되었다)를 factor(0.9)배 하겠다는 의미이다. 그리고 ES는 EarlyStopping라는 메소드를 정의한 것으로, monitor(‘val_loss’)가 patience(200) epochs동안 mode(여기서는 ‘min’으로, 최소값이 아니라면 작동한다는 뜻이다.)를 기준으로 삼아 만족하지 못한다면 학습을 일찍 종료하는 메소드이다. 또한 restore_best_weight를 True로 설정하면 이전 기록중에서 val_loss가 mode에 가장 부합하는 epoch의 가중치들을 최종 학습결과로 가져오게 된다. 위 두 메소드는 overfitting을 해소하기에 매우 적합한 방법들로, 본인의 model이 overfitting되고 있다면 사용함이 바람직하다.</p><p>이렇게 설정한 뒤 실행하면 다음과 같은 메세지들이 출력된다.</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre>Epoch 1/3000
23/23 [==============================] - 3s 10ms/step - loss: 1.1988 - accuracy: 0.0976 - val_loss: 0.1234 - val_accuracy: 0.1235 - lr: 0.0100
Epoch 2/3000
23/23 [==============================] - 0s 4ms/step - loss: 0.0845 - accuracy: 0.1636 - val_loss: 0.0848 - val_accuracy: 0.2037 - lr: 0.0100
Epoch 3/3000
23/23 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.1883 - val_loss: 0.0496 - val_accuracy: 0.1975 - lr: 0.0100
Epoch 4/3000
23/23 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.1876 - val_loss: 0.0423 - val_accuracy: 0.1975 - lr: 0.0100


...(중략)


Epoch 400/3000
23/23 [==============================] - 0s 4ms/step - loss: 3.0501e-04 - accuracy: 0.1945 - val_loss: 0.0185 - val_accuracy: 0.1975 - lr: 3.4337e-04
Epoch 401/3000
19/23 [=======================&gt;......] - ETA: 0s - loss: 3.2039e-04 - accuracy: 0.1990Restoring model weights from the end of the best epoch: 201.
23/23 [==============================] - 0s 4ms/step - loss: 3.9314e-04 - accuracy: 0.1945 - val_loss: 0.0193 - val_accuracy: 0.1975 - lr: 3.4337e-04
Epoch 401: early stopping
</pre></table></code></div></div><p>Learning rate(lr)가 epoch가 진행될수록 낮아지고, 401 epoch에서 학습이 멈춘 것으로 보아 early stopping 모두 잘 작동함을 알 수 있다. Loss가 학습이 진행될 수록 낮아지고 있고, accuracy 또한 미약하지만 증가하고 있으므로 학습이 잘 진행었다. 여기서 accuracy가 왜이렇게 낮은지 의문점을 가질 수 있는데, 변명같지만 dataset을 보면 사람도 구분이 어려운 숫자가 여럿 있기 때문에 그런 것이라고 해두자.</p><h4 id="학습-결과-확인"><span class="mr-2">학습 결과 확인</span><a href="#학습-결과-확인" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">random</span> <span class="c1">#test data을 랜덤으로 뽑기 위해 import
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span> <span class="c1">#학습된 model에 test x값을 넣어 예측값을 구함
</span><span class="n">real_ytest</span> <span class="o">=</span> <span class="n">min_max_scaler</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">y_test</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="s">'int64'</span><span class="p">)</span>
<span class="n">real_ypred</span> <span class="o">=</span> <span class="n">min_max_scaler</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">y_pred</span><span class="p">).</span><span class="nb">round</span><span class="p">().</span><span class="n">astype</span><span class="p">(</span><span class="s">'int64'</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_pred</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">:</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">img_test</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">labelsize</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"actual num :%d"</span> <span class="o">%</span><span class="n">real_ytest</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"predict num : %d"</span> <span class="o">%</span><span class="n">real_ypred</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p>Data 손질 과정에서 x,y값을 min_max scaler로 정규화 해준 것을 기억할 것이다. 이렇게 정의한 정규화는 inverse_transform을 통해 원상태로 돌릴 수 있다. 뒤에 astype(‘int64’)(타입을 정수로 바꾸기), round()(반올림 메소드)는 dataset의 output이 정수임을 고려하여 추가한 것이다. 이하 sample에서는 예측값을 랜덤하게 10개 선택하도록 코드를 작성하여 학습이 잘 이루어졌는지 확인하는 과정을 가졌다.</p><p><img data-src="https://github.com/44isOutlaw/44isOutlaw.github.io/blob/master/assets/img/DNN/r1.png?raw=true" alt="r1" data-proofer-ignore> <img data-src="https://github.com/44isOutlaw/44isOutlaw.github.io/blob/master/assets/img/DNN/r2.png?raw=true" alt="r2" data-proofer-ignore></p><p>위 코드를 입력하면 이러한 결과물이 나오는데, 분명 몇개는 잘 맞추지만 틀리는 것도 존재한다. 하지만 왜 틀렸는지 납득이 간다. Accuracy가 이상하게 값이 낮은 이유가 있다고 생각된다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>6/6 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.2278
</pre></table></code></div></div><p>또한, 정량적인 지표는 evaluate를 이용하여 얻을 수 있다. Test값을 이용하여 얻은 loss 또는 accuracy값은 model의 학습 정도의 정량적인 지표로 이용할 수 있을 것이다.</p><h2 id="ⅳ-결론"><span class="mr-2">Ⅳ. 결론</span><a href="#ⅳ-결론" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>이렇게 본문에서는 NN 및 DNN에 대하여, 그리고 keras를 이용하여 DNN model을 설계하는 과정을 살펴보았다. 다른 Machine learning model을 만드는 경우에도</p><h4 id="data-손질-1"><span class="mr-2">Data 손질</span><a href="#data-손질-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><h4 id="model-정의-및-학습-1"><span class="mr-2">Model 정의 및 학습</span><a href="#model-정의-및-학습-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><h4 id="학습-결과-확인-1"><span class="mr-2">학습 결과 확인</span><a href="#학습-결과-확인-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>과 같은 process를 거의 벗어나지 않으므로, 이를 사용하는데 크게 어려움이 없다. 하지만, model의 정확도를 향상시키는 방법은 조금 어려움이 있으며, 타인이 비슷한 상황에서 만든 model을 참고하고 keras의 내부 기능을 최대한 활용하여 오랜 시간 진행해보아야 할 것이라고 생각된다.</p></div><div class="post-tail-wrapper text-muted"><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Dnn%EC%9D%84+%EC%9D%B4%EC%9A%A9%ED%95%9C+%EB%8D%B0%EC%9D%B4%ED%84%B0+%EB%B6%84%EB%A5%98+-+Toolbox+44&url=https%3A%2F%2F44isoutlaw.github.io%2Fposts%2FDNN%25EC%259D%2584-%25EC%259D%25B4%25EC%259A%25A9%25ED%2595%259C-%25EB%258D%25B0%25EC%259D%25B4%25ED%2584%25B0-%25EB%25B6%2584%25EB%25A5%2598%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Dnn%EC%9D%84+%EC%9D%B4%EC%9A%A9%ED%95%9C+%EB%8D%B0%EC%9D%B4%ED%84%B0+%EB%B6%84%EB%A5%98+-+Toolbox+44&u=https%3A%2F%2F44isoutlaw.github.io%2Fposts%2FDNN%25EC%259D%2584-%25EC%259D%25B4%25EC%259A%25A9%25ED%2595%259C-%25EB%258D%25B0%25EC%259D%25B4%25ED%2584%25B0-%25EB%25B6%2584%25EB%25A5%2598%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2F44isoutlaw.github.io%2Fposts%2FDNN%25EC%259D%2584-%25EC%259D%25B4%25EC%259A%25A9%25ED%2595%259C-%25EB%258D%25B0%25EC%259D%25B4%25ED%2584%25B0-%25EB%25B6%2584%25EB%25A5%2598%2F&text=Dnn%EC%9D%84+%EC%9D%B4%EC%9A%A9%ED%95%9C+%EB%8D%B0%EC%9D%B4%ED%84%B0+%EB%B6%84%EB%A5%98+-+Toolbox+44" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/LSTM%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D/"><div class="card-body"> <em class="small" data-ts="1659884400" data-df="ll" > Aug 8, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Lstm을 이용한 데이터 분석</h3><div class="text-muted small"><p> RNN을 이용한 시계열 데이터 분석 Ⅰ. Intro Machine learning을 이용하여 시간축이 있는 데이터를 학습하기 위해서는 어느 데이터의 이전 시간, 그리고 다음 시간의 정보가 반영되어야만 한다. 하지만 기존의 NN은 한 샘플의 전후 데이터가 반영되지 않는 바, 이러한 시계열 데이터를 다루기 위한 새로운 model이 고안되었으니 이것이 ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"><div class="btn btn-outline-primary disabled" prompt="Older"><p>-</p></div><a href="/posts/LSTM%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D/" class="btn btn-outline-primary" prompt="Newer"><p>Lstm을 이용한 데이터 분석</p></a></div></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://twitter.com/username">your_full_name</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/ko.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
